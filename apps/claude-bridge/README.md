# claude-bridge

Use non-Anthropic models (OpenAI, Google) with Claude Code by proxying and transforming requests.

## What it does

Claude Code only works with Anthropic's Claude models. `claude-bridge` intercepts Claude Code's API calls and forwards them to other LLM providers like OpenAI or Google, allowing you to use GPT-4, Gemini, and other models within Claude Code's interface.

## Usage

```bash
# Use OpenAI GPT-4o with Claude Code (defaults to chat mode)
claude-bridge --provider openai --model gpt-4o

# Use Google Gemini with a specific prompt in Claude Code headless mode
claude-bridge --provider google --model gemini-1.5-pro --run-with -p "Hello world"

# Use custom API key
claude-bridge --provider openai --model gpt-4o --apiKey sk-...

# Use custom log directory
claude-bridge --provider google --model gemini-1.5-pro --log-dir ./my-logs
```

### Options

- `--provider <provider>` - LLM provider (openai, google)
- `--model <model>` - Model name (e.g., gpt-4o, gemini-1.5-pro)
- `--apiKey <key>` - API key (optional, uses env vars)
- `--log-dir <dir>` - Log directory (default: .claude-bridge)
- `--run-with <args...>` - Claude Code arguments (default: chat)

### Environment Variables

- `OPENAI_API_KEY` - OpenAI API key
- `GOOGLE_API_KEY` - Google API key

## Development

### Architecture

```
Claude Code â†’ claude-bridge (intercept) â†’ Transform â†’ Provider API â†’ Transform â†’ Stream back
```

**Core Components:**

- **CLI** (`src/cli.ts`) - Command-line interface and process management
- **Interceptor** (`src/interceptor.ts`) - Fetch interception and request/response logging
- **Types** (`src/types.ts`) - TypeScript interfaces and types
- **Loader** (`src/interceptor-loader.js`) - CommonJS loader for tsx/node compatibility

**How it works:**

1. **Interception**: Instruments `global.fetch()` to catch calls to `api.anthropic.com/v1/messages`
2. **Logging**: Raw requests logged to `{logDir}/requests-{timestamp}.jsonl`
3. **Debug Info**: Interceptor logs to `{logDir}/log.txt` (avoids stdout pollution)
4. **Transformation**: _(TODO)_ Convert Anthropic format â†’ lemmy unified â†’ target provider
5. **Forwarding**: _(TODO)_ Send to OpenAI/Google APIs and stream response back

### Project Structure

```
src/
â”œâ”€â”€ cli.ts                  # CLI entry point with commander
â”œâ”€â”€ interceptor.ts          # Fetch interception + file logging
â”œâ”€â”€ interceptor-loader.js   # CommonJS loader for tsx compatibility
â”œâ”€â”€ types.ts               # TypeScript interfaces
â””â”€â”€ index.ts               # Package exports

test/
â””â”€â”€ smoke.test.ts          # Integration tests (4 tests)

dist/                      # Compiled JavaScript output
```

### Building & Testing

```bash
# Install dependencies (from monorepo root)
npm install

# Build lemmy package first (required dependency)
cd packages/lemmy && npm run build && cd ../..

# Build claude-bridge
cd apps/claude-bridge
npm run build

# Run tests
npm run test:run

# Type checking
npm run typecheck
```

### Development Workflow

**VSCode Debug Setup:**

1. Set breakpoints in `src/cli.ts` or `src/interceptor.ts`
2. Open JavaScript Debug Terminal in VSCode
3. Run: `npx tsx --inspect src/cli.ts --provider openai --model gpt-4o`
4. Debugger will attach automatically

**Quick Testing:**

```bash
# Test CLI help
npx tsx src/cli.ts --help

# Test with minimal args (defaults to chat)
npx tsx src/cli.ts --provider openai --model gpt-4o

# Test interception (will fail on claude executable but logs are created)
OPENAI_API_KEY=sk-test npx tsx src/cli.ts --provider openai --model gpt-4o --log-dir ./test-logs
```

**Log Inspection:**

```bash
# Check interception logs
cat .claude-bridge/log.txt

# Check raw requests (when Claude actually makes calls)
cat .claude-bridge/requests-*.jsonl | jq
```

### Current Status

- âœ… **Fetch Interception**: Working - captures v1/messages calls
- âœ… **File Logging**: Working - requests.jsonl + log.txt
- âœ… **CLI Interface**: Working - all arguments and validation
- âœ… **Testing**: Working - 4 smoke tests passing
- ðŸ”„ **Request Transformation**: TODO - Anthropic â†’ lemmy â†’ provider format
- ðŸ”„ **Provider Forwarding**: TODO - Call OpenAI/Google APIs
- ðŸ”„ **Response Streaming**: TODO - Forward SSE back to Claude Code

### Next Steps

1. Implement request transformation using lemmy package
2. Add provider-specific API calls (OpenAI/Google)
3. Stream provider responses back as Anthropic-compatible SSE
4. Add more comprehensive testing with real API calls
